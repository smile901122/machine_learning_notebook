{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# stacking 算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## base model 类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import abstractmethod, ABCMeta\n",
    "\n",
    "# base model\n",
    "class BaseModel(metaclass=ABCMeta):\n",
    "    \n",
    "    @abstractmethod\n",
    "    def fit(self, x_train, y_train, x_val, y_val):\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def predict(self, x):\n",
    "        pass\n",
    "    \n",
    "    def load_model(self, model_file):\n",
    "        pass\n",
    "    \n",
    "    def save_model(self, model_file):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## stacking 类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "\n",
    "# stacking\n",
    "class Stacking(BaseEstimator, TransformerMixin, RegressorMixin):\n",
    "    def __init__(self, base_models, meta_model, k_folds=5):\n",
    "        self.base_models = base_models\n",
    "        self.meta_model = meta_model\n",
    "        self.k_folds = k_folds\n",
    "    \n",
    "    def train(self, x_train, y_train):\n",
    "        self.base_models_ = [list() for x in self.base_models]\n",
    "        self.meta_model_ = clone(self.meta_model)\n",
    "        \n",
    "        kfold = KFold(n_splits=self.k_folds, shuffle=True, random_state=2019)\n",
    "\n",
    "        # 使用K-fold的方法来进行交叉验证，将每次验证的结果作为新的特征来进行处理\n",
    "        out_of_fold_predictions = np.zeros((x_train.shape[0], len(self.base_models)))\n",
    "        \n",
    "        for i, model in enumerate(self.base_models):\n",
    "            for train_index, holdout_index in kfold.split(x_train, y_train):\n",
    "                instance = clone(model)\n",
    "                # 保存 base_model 中每个 model 的实例\n",
    "                self.base_models_[i].append(instance)\n",
    "                # 训练 model 实例\n",
    "                instance.fit(x_train[train_index],  y_train[train_index])\n",
    "                # 预测 k_fold 中 validation 那部分\n",
    "                y_pred = instance.predict(x_train[holdout_index])\n",
    "                # 保存所有 model 的结果作为下层训练数据\n",
    "                out_of_fold_predictions[holdout_index, i] = y_pred\n",
    "\n",
    "        # 将交叉验证预测出的结果 和 训练集中的标签值进行训练\n",
    "        self.meta_model_.fit(out_of_fold_predictions, y_train)\n",
    "        return self\n",
    "        \n",
    "    def predict(self, x_predict):\n",
    "        # 对于每个 base_model 的 k 个 models 的预测结果求均值作为该 base_model 的预测结果\n",
    "        # 将所有的 base_model 的预测结果拼接起来作为 meta_model 的 feature\n",
    "        meta_features = np.column_stack([\n",
    "            np.column_stack([model.predict(x_predict) for model in base_models]).mean(axis=1)\n",
    "            for base_models in self.base_models_])\n",
    "        print(meta_features)\n",
    "        \n",
    "        return self.meta_model_.predict(meta_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 保存和加载模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "def save_model(cls, model_file):\n",
    "    joblib.dump(cls, model_file)\n",
    "    \n",
    "def load_model(model_file):\n",
    "    cls = joblib.load(model_file)\n",
    "    return cls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## stacking 的使用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 加载数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iris keys:  dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names', 'filename'])\n",
      "x_train shape:  (105, 4)  y_train shape:  (105,)\n",
      "x_test shape:  (45, 4)  y_test shape:  (45,)\n"
     ]
    }
   ],
   "source": [
    "# 数据\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "iris=load_iris()\n",
    "print('iris keys: ', iris.keys())\n",
    "\n",
    "x_data = iris.data\n",
    "y_data = iris.target\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.3, random_state=2019)\n",
    "print('x_train shape: ', x_train.shape, ' y_train shape: ', y_train.shape)\n",
    "print('x_test shape: ', x_test.shape, ' y_test shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The score of linear is : 1.000000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_clf = SVC(kernel='linear')  # kernel = 'linear'\n",
    "\n",
    "svm_clf.fit(x_train, y_train)\n",
    "\n",
    "score = svm_clf.score(x_test, y_test)\n",
    "print(\"The score of linear is : %f\" % score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The score of linear is : 0.933333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "\n",
    "lr_clf = LR(multi_class='ovr')\n",
    "\n",
    "lr_clf.fit(x_train, y_train)\n",
    "\n",
    "score = lr_clf.score(x_test, y_test)\n",
    "print(\"The score of linear is : %f\" % score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 2 1 2 0 2 0 1 2 2 2 2 1 0 1 2 1 0 2 0 2 0 1 0 0 1 2 0 0 2 0 0 2 2 0 0\n",
      " 2 0 2 0 1 0 2 1] [0 0 2 1 2 0 2 0 1 2 2 2 2 1 0 1 2 1 0 2 0 2 0 1 0 0 1 2 0 0 2 0 0 2 2 0 0\n",
      " 2 0 1 0 1 0 2 1]\n",
      "0.9777777777777777\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "params_sklearn = {\n",
    "    'learning_rate':0.1,\n",
    "    'max_bin':150,\n",
    "    'num_leaves':32,    \n",
    "    'max_depth':11,\n",
    "    \n",
    "    'reg_alpha':0.1,\n",
    "    'reg_lambda':0.2,   \n",
    "     \n",
    "    'objective':'multiclass',\n",
    "    'n_estimators':300,\n",
    "    #'class_weight':weight\n",
    "}\n",
    "\n",
    "lgb_clf = lgb.LGBMClassifier(**params_sklearn)\n",
    "\n",
    "lgb_clf.fit(x_train, y_train)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = lgb_clf.predict(x_test)\n",
    "print(y_pred, y_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 2 1 2 0 2 0 1 2 2 2 2 1 0 1 2 1 0 2 0 2 0 1 0 0 1 2 0 0 2 0 0 2 2 0 0\n",
      " 2 0 2 0 1 0 2 1] [0 0 2 1 2 0 2 0 1 2 2 2 2 1 0 1 2 1 0 2 0 2 0 1 0 0 1 2 0 0 2 0 0 2 2 0 0\n",
      " 2 0 1 0 1 0 2 1]\n",
      "0.9777777777777777\n"
     ]
    }
   ],
   "source": [
    "# import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "params = {\n",
    "    'eta': 0.3,\n",
    "    'max_depth':3,   \n",
    "    'min_child_weight':1,\n",
    "    'gamma':0.3, \n",
    "    'subsample':0.8,\n",
    "    'colsample_bytree':0.8,\n",
    "    'booster':'gbtree',\n",
    "    'objective': 'multiclass',\n",
    "    'lambda':1,  \n",
    "    'seed':2019,\n",
    "}\n",
    "\n",
    "xgb_clf = XGBClassifier(**params)\n",
    "\n",
    "xgb_clf.fit(x_train, y_train)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = xgb_clf.predict(x_test)\n",
    "print(y_pred, y_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用 stacking "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Stacking(base_models=[LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                         fit_intercept=True,\n",
       "                                         intercept_scaling=1, l1_ratio=None,\n",
       "                                         max_iter=100, multi_class='ovr',\n",
       "                                         n_jobs=None, penalty='l2',\n",
       "                                         random_state=None, solver='warn',\n",
       "                                         tol=0.0001, verbose=0,\n",
       "                                         warm_start=False),\n",
       "                      LGBMClassifier(boosting_type='gbdt', class_weight=None,\n",
       "                                     colsample_bytree=1.0,\n",
       "                                     importance_type='sp...\n",
       "         meta_model=XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                                  colsample_bylevel=1, colsample_bynode=1,\n",
       "                                  colsample_bytree=0.8, eta=0.3, gamma=0.3,\n",
       "                                  lambda=1, learning_rate=0.1, max_delta_step=0,\n",
       "                                  max_depth=3, min_child_weight=1, missing=None,\n",
       "                                  n_estimators=100, n_jobs=1, nthread=None,\n",
       "                                  objective='multi:softprob', random_state=0,\n",
       "                                  reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "                                  seed=2019, silent=None, subsample=0.8,\n",
       "                                  verbosity=1))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "stacking_model = Stacking(base_models=[lr_clf, lgb_clf, svm_clf], meta_model=xgb_clf, k_folds=5)\n",
    "\n",
    "stacking_model.train(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.  0.  0. ]\n",
      " [0.  0.  0. ]\n",
      " [2.  2.  2. ]\n",
      " [1.  1.  1. ]\n",
      " [1.6 2.  2. ]\n",
      " [0.  0.  0. ]\n",
      " [2.  2.  2. ]\n",
      " [0.  0.  0. ]\n",
      " [2.  1.2 1. ]\n",
      " [2.  2.  2. ]\n",
      " [1.  1.8 2. ]\n",
      " [1.6 2.  2. ]\n",
      " [2.  2.  2. ]\n",
      " [1.  1.  1. ]\n",
      " [0.  0.  0. ]\n",
      " [1.  1.  1. ]\n",
      " [2.  2.  2. ]\n",
      " [1.  1.  1. ]\n",
      " [0.  0.  0. ]\n",
      " [1.8 2.  2. ]\n",
      " [0.  0.  0. ]\n",
      " [2.  2.  2. ]\n",
      " [0.  0.  0. ]\n",
      " [1.  1.  1. ]\n",
      " [0.  0.  0. ]\n",
      " [0.  0.  0. ]\n",
      " [1.  1.  1. ]\n",
      " [1.8 2.  2. ]\n",
      " [0.  0.  0. ]\n",
      " [0.  0.  0. ]\n",
      " [2.  2.  2. ]\n",
      " [0.  0.  0. ]\n",
      " [0.  0.  0. ]\n",
      " [2.  2.  2. ]\n",
      " [2.  2.  2. ]\n",
      " [0.  0.  0. ]\n",
      " [0.  0.  0. ]\n",
      " [2.  2.  2. ]\n",
      " [0.  0.  0. ]\n",
      " [1.  1.8 1. ]\n",
      " [0.  0.  0. ]\n",
      " [1.  1.  1. ]\n",
      " [0.  0.  0. ]\n",
      " [1.4 2.  2. ]\n",
      " [1.8 1.  1. ]]\n",
      "[0 0 2 1 2 0 2 0 1 2 2 2 2 1 0 1 2 1 0 2 0 2 0 1 0 0 1 2 0 0 2 0 0 2 2 0 0\n",
      " 2 0 1 0 1 0 2 1] [0 0 2 1 2 0 2 0 1 2 2 2 2 1 0 1 2 1 0 2 0 2 0 1 0 0 1 2 0 0 2 0 0 2 2 0 0\n",
      " 2 0 1 0 1 0 2 1]\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = stacking_model.predict(x_test)\n",
    "print(y_pred, y_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
